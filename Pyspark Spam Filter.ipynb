{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e107272-6e84-4a40-bc12-cc97a1db7090",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "- The objective from this project is to prepare text data with **`NLP techniques`** and  create a <b>Spam filter using NaiveBayes classifier</b>.\n",
    "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566198b6-04ae-4984-b489-a2010878b541",
   "metadata": {},
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20eac75-a491-477b-b930-e319236b6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.118.129:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e3914187a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eb86839-6af2-4dcc-8c4c-3031fb98d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as fn\n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer,RegexTokenizer,StopWordsRemover,IDF ,HashingTF ,VectorAssembler , Word2Vec ,MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes , MultilayerPerceptronClassifier , RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad82e721-6cbf-4f66-b736-f49f462a2e01",
   "metadata": {},
   "source": [
    "### Read the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f25c9d1-95f4-4813-8cdc-e03695ec0f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"delimiter\", \"\t\").csv('SMSSpamCollection')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef3f93a-ca0d-44cd-9b48-6d8de4a09778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rename = df.withColumnRenamed('_c0' , 'class').withColumnRenamed('_c1' , 'text')\n",
    "df_rename.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f224e6e0-d5c0-4047-a4f8-d3e78ff3f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|class|text                                                                                                                                                            |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
      "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
      "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
      "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
      "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
      "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
      "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
      "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
      "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
      "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rename.show(10 ,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0c5314-dc93-4a80-99a3-808197f65806",
   "metadata": {},
   "source": [
    "## Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf05575-285c-439a-acb6-2596b9f0c355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "+-----+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new feature column contains the length of the text column\n",
    "df_length = df_rename.withColumn('length' , fn.length(col('text')))\n",
    "df_length.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81a9c74-abf8-4ac9-8051-563290f930ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the average text length for each class\n",
    "df_length.groupby('class').avg('length').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62289ae-cb47-4cab-afa9-a713e4547fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|class|text|length|\n",
      "+-----+----+------+\n",
      "|    0|   0|     0|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Null values\n",
    "df_length.select([fn.count(fn.when(fn.isnull(c), c)).alias(c) for c in df_length.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48dd2940-4639-4575-b48f-3db651ed596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+\n",
      "|class|                text|length|count|\n",
      "+-----+--------------------+------+-----+\n",
      "| spam|Congrats! 1 year ...|   160|    2|\n",
      "|  ham|God picked up a f...|   128|    2|\n",
      "|  ham|Did u got that pe...|    28|    3|\n",
      "| spam|18 days to Euro20...|   135|    2|\n",
      "|  ham|Whatsup there. Do...|    35|    2|\n",
      "|  ham|Reverse is cheati...|    45|    2|\n",
      "| spam|Want to funk up u...|   155|    2|\n",
      "|  ham|When people see m...|   148|    2|\n",
      "| spam|FREE for 1st week...|   158|    3|\n",
      "|  ham|No no. I will che...|    46|    3|\n",
      "|  ham|                 Ok.|     3|    4|\n",
      "|  ham|Gud ni8 dear..slp...|    53|    2|\n",
      "|  ham|Night has ended f...|   156|    3|\n",
      "| spam|WIN: We have a wi...|   132|    2|\n",
      "|  ham|No calls..message...|    32|    3|\n",
      "|  ham|Good morning prin...|    35|    2|\n",
      "|  ham|If you r @ home t...|    43|    2|\n",
      "|  ham|Today is ACCEPT D...|   156|    3|\n",
      "| spam|Natalja (25/F) is...|   136|    2|\n",
      "|  ham|Love isn't a deci...|   126|    2|\n",
      "+-----+--------------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Duplicates\n",
    "grouped_df = df_length.groupBy(df_length.columns).count()\n",
    "duplicate_records = grouped_df.filter(col(\"count\") > 1)\n",
    "duplicate_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40d6c49-a45a-4e5c-ad4b-e00008c9defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_length.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6591c7dd-aa03-4895-8890-31e9a9fb57d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Duplicates\n",
    "df_duplicates = df_length.dropDuplicates()\n",
    "df_duplicates.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906dd2b5-a183-47c3-a8f1-46258e52fab8",
   "metadata": {},
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4897c0f4-fbea-40f5-a747-5e1efe0e8f0f",
   "metadata": {},
   "source": [
    "##### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1ca15d-118e-4b90-8059-071f9c13f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|class|text                                                                                                                                  |length|\n",
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|ham  |Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?|134   |\n",
      "|ham  |I see a cup of coffee animation                                                                                                       |31    |\n",
      "|ham  |hanks lotsly!                                                                                                                         |13    |\n",
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Starting with remove anything not a letter\n",
    "#df_filtered = df_duplicates.withColumn('text_filtered' , fn.regexp_replace(col('text') , '[^A-Za-z ]+', ''))\n",
    "\n",
    "#Remove any digits from text \n",
    "#df_filtered = df_filtered.withColumn('text_filtered' , fn.regexp_replace(col('text_filtered') , '\\d+', ''))\n",
    "\n",
    "#Remove any multiple spaces\n",
    "#df_filtered = df_filtered.withColumn(\"text_filtered\",regexp_replace(col('text_filtered'), ' +', ' '))\n",
    "df_filtered = df_duplicates\n",
    "df_filtered.show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d46b0b-a189-48c4-859d-9bbbf90add45",
   "metadata": {},
   "source": [
    "#### Most of spam sms have digits and punctuation so decide to keep it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b93c7-1b14-43cd-9049-c95a5c81d13f",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "##### 1)transform text into tokens and remove stop words\n",
    "##### 2) Apply count Vectorizer then idf to transform each word to vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329c9804-7da5-4bfe-b388-9d4c5fda8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "#Remove Stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "#Apply CountVectorizer to get term frequencies\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectorized\")\n",
    "\n",
    "# Apply IDF to get TF-IDF features\n",
    "idf = IDF(inputCol=\"vectorized\", outputCol=\"feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc4ac56-472e-4a38-b514-9263c50b2ec1",
   "metadata": {},
   "source": [
    "Convert the <b>class column</b> to index using <b>StringIndexer</b> then create <b>features Column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1af6f9-1335-40f8-8278-bfca00910f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert column class to 0,1\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "\n",
    "#Using Vector Assmbeler to creater features column\n",
    "vectorAssm = VectorAssembler(inputCols=['feature','length'] , outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361a6b5-f41c-46cc-8537-2890cbea9631",
   "metadata": {},
   "source": [
    "#### Create Navie Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368cfe20-464c-4bc3-b016-c7fc3e033390",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7609e1-2006-4d50-ba29-bbbe03e830c7",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "##### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e0c779-7184-4045-a887-24652b532df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [regexTokenizer , remover , cv , idf , indexer ,vectorAssm ,nv]\n",
    "pl = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a344b38-d94e-4148-bddd-c0b704df0989",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "879d859c-672b-4195-a44c-13432a5117ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3680 rows in the training set, and 1491 in the test set\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_filtered.randomSplit([0.7, 0.3], seed=42)\n",
    "print(f\"There are {train_data.count()} rows in the training set, and {test_data.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dea41-198c-4d07-bac5-bd37e995ee4c",
   "metadata": {},
   "source": [
    "#### Fitting Pipeline model to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b112e0e-40c9-46f4-8ce3-605de98d977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+--------------------+\n",
      "|            features|label|prediction|         probability|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "|(7056,[7,9,3633,4...|  0.0|       0.0|[1.0,1.0460178600...|\n",
      "|(7056,[7,9,31,105...|  0.0|       0.0|[1.0,7.8828700561...|\n",
      "|(7056,[502,783,48...|  0.0|       0.0|[0.99999990788599...|\n",
      "|(7056,[10,12,68,1...|  0.0|       0.0|[1.0,3.0612301226...|\n",
      "|(7056,[16,19,89,9...|  0.0|       0.0|[1.0,1.1236961980...|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 21:28:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "model = pl.fit(train_data)\n",
    "train_pred = model.transform(train_data)\n",
    "train_pred.select('features' , 'label','prediction','probability').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18badf-d18c-40ce-bb14-cc7896989271",
   "metadata": {},
   "source": [
    "#### Perform predictions on tests dataframe and evaluate using F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f5b48c3-df13-489f-86fb-8482ff473fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+--------------------+\n",
      "|            features|label|prediction|         probability|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "|(7056,[3,7,9,18,1...|  0.0|       0.0|[1.0,6.4243448789...|\n",
      "|(7056,[19,96,219,...|  0.0|       0.0|[1.0,3.3821504127...|\n",
      "|(7056,[0,91,244,5...|  0.0|       1.0|[1.53625302005278...|\n",
      "|(7056,[7,9,370,89...|  0.0|       0.0|[1.0,1.5204975380...|\n",
      "|(7056,[0,1,6,26,3...|  0.0|       0.0|[1.0,2.9858067624...|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.transform(test_data)\n",
    "test_pred.select('features' , 'label','prediction','probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00bfe7c4-a8fd-453e-b9e2-50e968209a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9765973726873007\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(test_pred)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d24a7-d3a8-47bf-bcff-b791252e49f9",
   "metadata": {},
   "source": [
    "#### Trying Randomforest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace1101b-848f-48a6-8fa8-01ca102f0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(maxDepth=20 , numTrees=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "619f212a-a75d-4c94-ab70-4da2e1e5ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 21:29:05 WARN DAGScheduler: Broadcasting large task binary with size 1021.4 KiB\n",
      "24/05/11 21:29:05 WARN DAGScheduler: Broadcasting large task binary with size 1052.4 KiB\n",
      "24/05/11 21:29:05 WARN DAGScheduler: Broadcasting large task binary with size 1088.2 KiB\n",
      "24/05/11 21:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1118.4 KiB\n",
      "24/05/11 21:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1151.5 KiB\n",
      "24/05/11 21:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1183.3 KiB\n",
      "24/05/11 21:29:06 WARN DAGScheduler: Broadcasting large task binary with size 1217.5 KiB\n",
      "24/05/11 21:29:07 WARN DAGScheduler: Broadcasting large task binary with size 1256.2 KiB\n",
      "24/05/11 21:29:07 WARN DAGScheduler: Broadcasting large task binary with size 1293.3 KiB\n",
      "24/05/11 21:29:07 WARN DAGScheduler: Broadcasting large task binary with size 1333.5 KiB\n",
      "24/05/11 21:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1369.9 KiB\n",
      "24/05/11 21:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1402.6 KiB\n",
      "24/05/11 21:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1439.7 KiB\n",
      "24/05/11 21:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1475.3 KiB\n",
      "24/05/11 21:29:09 WARN DAGScheduler: Broadcasting large task binary with size 1515.0 KiB\n"
     ]
    }
   ],
   "source": [
    "stages = [regexTokenizer , remover , cv , idf , indexer,vectorAssm ,rf]\n",
    "pl = Pipeline(stages=stages)\n",
    "\n",
    "\n",
    "model = pl.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34fb4fc5-4808-4c2f-804c-79cedd71731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 21:29:48 WARN DAGScheduler: Broadcasting large task binary with size 1120.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9455975586448901\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.transform(test_data)\n",
    "f1_score = evaluator.evaluate(test_pred)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81b3df-3fde-4360-b7ac-4e6152ce44f7",
   "metadata": {},
   "source": [
    "#### let's try with kfold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c367f18b-e05c-4924-b284-eea3c03e70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50]) \\\n",
    "    .addGrid(rf.maxDepth, [30]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "828828e4-6691-4f8c-9697-ddd9b9f77e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=pl,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd44899e-edf0-457d-8c9c-9887f583ecdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 21:31:22 WARN DAGScheduler: Broadcasting large task binary with size 1005.6 KiB\n",
      "24/05/11 21:31:27 WARN DAGScheduler: Broadcasting large task binary with size 1037.1 KiB\n",
      "24/05/11 21:31:31 WARN DAGScheduler: Broadcasting large task binary with size 1073.3 KiB\n",
      "24/05/11 21:31:35 WARN DAGScheduler: Broadcasting large task binary with size 1109.8 KiB\n",
      "24/05/11 21:31:40 WARN DAGScheduler: Broadcasting large task binary with size 1143.0 KiB\n",
      "24/05/11 21:31:44 WARN DAGScheduler: Broadcasting large task binary with size 1180.7 KiB\n",
      "24/05/11 21:31:48 WARN DAGScheduler: Broadcasting large task binary with size 1217.1 KiB\n",
      "24/05/11 21:31:52 WARN DAGScheduler: Broadcasting large task binary with size 1255.9 KiB\n",
      "24/05/11 21:31:56 WARN DAGScheduler: Broadcasting large task binary with size 1294.7 KiB\n",
      "24/05/11 21:32:00 WARN DAGScheduler: Broadcasting large task binary with size 1330.1 KiB\n",
      "24/05/11 21:32:04 WARN DAGScheduler: Broadcasting large task binary with size 1365.8 KiB\n",
      "24/05/11 21:32:08 WARN DAGScheduler: Broadcasting large task binary with size 1399.2 KiB\n",
      "24/05/11 21:32:12 WARN DAGScheduler: Broadcasting large task binary with size 1437.0 KiB\n",
      "24/05/11 21:32:16 WARN DAGScheduler: Broadcasting large task binary with size 1472.9 KiB\n",
      "24/05/11 21:32:20 WARN DAGScheduler: Broadcasting large task binary with size 1508.9 KiB\n",
      "24/05/11 21:32:24 WARN DAGScheduler: Broadcasting large task binary with size 1544.8 KiB\n",
      "24/05/11 21:32:28 WARN DAGScheduler: Broadcasting large task binary with size 1580.7 KiB\n",
      "24/05/11 21:32:32 WARN DAGScheduler: Broadcasting large task binary with size 1613.9 KiB\n",
      "24/05/11 21:32:36 WARN DAGScheduler: Broadcasting large task binary with size 1651.3 KiB\n",
      "24/05/11 21:32:39 WARN DAGScheduler: Broadcasting large task binary with size 1685.0 KiB\n",
      "24/05/11 21:32:43 WARN DAGScheduler: Broadcasting large task binary with size 1717.9 KiB\n",
      "24/05/11 21:32:49 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n",
      "24/05/11 21:32:53 WARN DAGScheduler: Broadcasting large task binary with size 1786.1 KiB\n",
      "24/05/11 21:33:05 WARN DAGScheduler: Broadcasting large task binary with size 1253.6 KiB\n",
      "24/05/11 21:33:43 WARN DAGScheduler: Broadcasting large task binary with size 1012.1 KiB\n",
      "24/05/11 21:33:48 WARN DAGScheduler: Broadcasting large task binary with size 1044.3 KiB\n",
      "24/05/11 21:33:51 WARN DAGScheduler: Broadcasting large task binary with size 1078.1 KiB\n",
      "24/05/11 21:33:54 WARN DAGScheduler: Broadcasting large task binary with size 1114.0 KiB\n",
      "24/05/11 21:33:58 WARN DAGScheduler: Broadcasting large task binary with size 1146.6 KiB\n",
      "24/05/11 21:34:01 WARN DAGScheduler: Broadcasting large task binary with size 1184.1 KiB\n",
      "24/05/11 21:34:05 WARN DAGScheduler: Broadcasting large task binary with size 1219.3 KiB\n",
      "24/05/11 21:34:09 WARN DAGScheduler: Broadcasting large task binary with size 1258.2 KiB\n",
      "24/05/11 21:34:12 WARN DAGScheduler: Broadcasting large task binary with size 1294.0 KiB\n",
      "24/05/11 21:34:16 WARN DAGScheduler: Broadcasting large task binary with size 1333.4 KiB\n",
      "24/05/11 21:34:20 WARN DAGScheduler: Broadcasting large task binary with size 1372.5 KiB\n",
      "24/05/11 21:34:23 WARN DAGScheduler: Broadcasting large task binary with size 1407.6 KiB\n",
      "24/05/11 21:34:27 WARN DAGScheduler: Broadcasting large task binary with size 1446.6 KiB\n",
      "24/05/11 21:34:31 WARN DAGScheduler: Broadcasting large task binary with size 1480.9 KiB\n",
      "24/05/11 21:34:36 WARN DAGScheduler: Broadcasting large task binary with size 1518.3 KiB\n",
      "24/05/11 21:34:40 WARN DAGScheduler: Broadcasting large task binary with size 1553.8 KiB\n",
      "24/05/11 21:34:45 WARN DAGScheduler: Broadcasting large task binary with size 1586.5 KiB\n",
      "24/05/11 21:34:49 WARN DAGScheduler: Broadcasting large task binary with size 1623.3 KiB\n",
      "24/05/11 21:34:53 WARN DAGScheduler: Broadcasting large task binary with size 1655.1 KiB\n",
      "24/05/11 21:34:57 WARN DAGScheduler: Broadcasting large task binary with size 1689.7 KiB\n",
      "24/05/11 21:35:03 WARN DAGScheduler: Broadcasting large task binary with size 1718.2 KiB\n",
      "24/05/11 21:35:08 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n",
      "24/05/11 21:35:13 WARN DAGScheduler: Broadcasting large task binary with size 1778.7 KiB\n",
      "24/05/11 21:35:19 WARN DAGScheduler: Broadcasting large task binary with size 1257.9 KiB\n",
      "24/05/11 21:35:51 WARN DAGScheduler: Broadcasting large task binary with size 1000.3 KiB\n",
      "24/05/11 21:35:54 WARN DAGScheduler: Broadcasting large task binary with size 1036.8 KiB\n",
      "24/05/11 21:35:57 WARN DAGScheduler: Broadcasting large task binary with size 1074.5 KiB\n",
      "24/05/11 21:36:01 WARN DAGScheduler: Broadcasting large task binary with size 1107.4 KiB\n",
      "24/05/11 21:36:06 WARN DAGScheduler: Broadcasting large task binary with size 1141.5 KiB\n",
      "24/05/11 21:36:10 WARN DAGScheduler: Broadcasting large task binary with size 1177.3 KiB\n",
      "24/05/11 21:36:13 WARN DAGScheduler: Broadcasting large task binary with size 1213.8 KiB\n",
      "24/05/11 21:36:17 WARN DAGScheduler: Broadcasting large task binary with size 1249.5 KiB\n",
      "24/05/11 21:36:21 WARN DAGScheduler: Broadcasting large task binary with size 1286.7 KiB\n",
      "24/05/11 21:36:24 WARN DAGScheduler: Broadcasting large task binary with size 1324.2 KiB\n",
      "24/05/11 21:36:28 WARN DAGScheduler: Broadcasting large task binary with size 1362.1 KiB\n",
      "24/05/11 21:36:32 WARN DAGScheduler: Broadcasting large task binary with size 1395.6 KiB\n",
      "24/05/11 21:36:36 WARN DAGScheduler: Broadcasting large task binary with size 1425.4 KiB\n",
      "24/05/11 21:36:39 WARN DAGScheduler: Broadcasting large task binary with size 1457.3 KiB\n",
      "24/05/11 21:36:43 WARN DAGScheduler: Broadcasting large task binary with size 1489.4 KiB\n",
      "24/05/11 21:36:47 WARN DAGScheduler: Broadcasting large task binary with size 1523.7 KiB\n",
      "24/05/11 21:36:50 WARN DAGScheduler: Broadcasting large task binary with size 1551.4 KiB\n",
      "24/05/11 21:36:54 WARN DAGScheduler: Broadcasting large task binary with size 1580.9 KiB\n",
      "24/05/11 21:36:58 WARN DAGScheduler: Broadcasting large task binary with size 1613.4 KiB\n",
      "24/05/11 21:37:02 WARN DAGScheduler: Broadcasting large task binary with size 1645.1 KiB\n",
      "24/05/11 21:37:06 WARN DAGScheduler: Broadcasting large task binary with size 1674.0 KiB\n",
      "24/05/11 21:37:10 WARN DAGScheduler: Broadcasting large task binary with size 1703.6 KiB\n",
      "24/05/11 21:37:15 WARN DAGScheduler: Broadcasting large task binary with size 1736.6 KiB\n",
      "24/05/11 21:37:22 WARN DAGScheduler: Broadcasting large task binary with size 1240.3 KiB\n",
      "24/05/11 21:37:55 WARN DAGScheduler: Broadcasting large task binary with size 1030.8 KiB\n",
      "24/05/11 21:37:58 WARN DAGScheduler: Broadcasting large task binary with size 1068.2 KiB\n",
      "24/05/11 21:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1104.5 KiB\n",
      "24/05/11 21:38:06 WARN DAGScheduler: Broadcasting large task binary with size 1139.3 KiB\n",
      "24/05/11 21:38:09 WARN DAGScheduler: Broadcasting large task binary with size 1178.0 KiB\n",
      "24/05/11 21:38:13 WARN DAGScheduler: Broadcasting large task binary with size 1213.1 KiB\n",
      "24/05/11 21:38:17 WARN DAGScheduler: Broadcasting large task binary with size 1247.9 KiB\n",
      "24/05/11 21:38:21 WARN DAGScheduler: Broadcasting large task binary with size 1279.8 KiB\n",
      "24/05/11 21:38:25 WARN DAGScheduler: Broadcasting large task binary with size 1316.2 KiB\n",
      "24/05/11 21:38:29 WARN DAGScheduler: Broadcasting large task binary with size 1346.3 KiB\n",
      "24/05/11 21:38:32 WARN DAGScheduler: Broadcasting large task binary with size 1381.6 KiB\n",
      "24/05/11 21:38:36 WARN DAGScheduler: Broadcasting large task binary with size 1414.0 KiB\n",
      "24/05/11 21:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1444.9 KiB\n",
      "24/05/11 21:38:44 WARN DAGScheduler: Broadcasting large task binary with size 1474.8 KiB\n",
      "24/05/11 21:38:48 WARN DAGScheduler: Broadcasting large task binary with size 1507.3 KiB\n",
      "24/05/11 21:38:52 WARN DAGScheduler: Broadcasting large task binary with size 1538.7 KiB\n",
      "24/05/11 21:38:55 WARN DAGScheduler: Broadcasting large task binary with size 1570.0 KiB\n",
      "24/05/11 21:38:59 WARN DAGScheduler: Broadcasting large task binary with size 1599.9 KiB\n",
      "24/05/11 21:39:03 WARN DAGScheduler: Broadcasting large task binary with size 1632.4 KiB\n",
      "24/05/11 21:39:07 WARN DAGScheduler: Broadcasting large task binary with size 1661.9 KiB\n",
      "24/05/11 21:39:11 WARN DAGScheduler: Broadcasting large task binary with size 1694.0 KiB\n",
      "24/05/11 21:39:17 WARN DAGScheduler: Broadcasting large task binary with size 1723.6 KiB\n",
      "24/05/11 21:39:25 WARN DAGScheduler: Broadcasting large task binary with size 1235.0 KiB\n",
      "24/05/11 21:39:57 WARN DAGScheduler: Broadcasting large task binary with size 1007.2 KiB\n",
      "24/05/11 21:40:01 WARN DAGScheduler: Broadcasting large task binary with size 1038.6 KiB\n",
      "24/05/11 21:40:04 WARN DAGScheduler: Broadcasting large task binary with size 1074.4 KiB\n",
      "24/05/11 21:40:08 WARN DAGScheduler: Broadcasting large task binary with size 1108.3 KiB\n",
      "24/05/11 21:40:12 WARN DAGScheduler: Broadcasting large task binary with size 1140.6 KiB\n",
      "24/05/11 21:40:16 WARN DAGScheduler: Broadcasting large task binary with size 1175.6 KiB\n",
      "24/05/11 21:40:20 WARN DAGScheduler: Broadcasting large task binary with size 1211.7 KiB\n",
      "24/05/11 21:40:23 WARN DAGScheduler: Broadcasting large task binary with size 1247.2 KiB\n",
      "24/05/11 21:40:28 WARN DAGScheduler: Broadcasting large task binary with size 1280.8 KiB\n",
      "24/05/11 21:40:32 WARN DAGScheduler: Broadcasting large task binary with size 1313.0 KiB\n",
      "24/05/11 21:40:36 WARN DAGScheduler: Broadcasting large task binary with size 1346.8 KiB\n",
      "24/05/11 21:40:40 WARN DAGScheduler: Broadcasting large task binary with size 1379.9 KiB\n",
      "24/05/11 21:40:44 WARN DAGScheduler: Broadcasting large task binary with size 1417.3 KiB\n",
      "24/05/11 21:40:48 WARN DAGScheduler: Broadcasting large task binary with size 1448.4 KiB\n",
      "24/05/11 21:40:52 WARN DAGScheduler: Broadcasting large task binary with size 1483.3 KiB\n",
      "24/05/11 21:40:56 WARN DAGScheduler: Broadcasting large task binary with size 1513.4 KiB\n",
      "24/05/11 21:41:00 WARN DAGScheduler: Broadcasting large task binary with size 1544.4 KiB\n",
      "24/05/11 21:41:06 WARN DAGScheduler: Broadcasting large task binary with size 1574.3 KiB\n",
      "24/05/11 21:41:11 WARN DAGScheduler: Broadcasting large task binary with size 1608.5 KiB\n",
      "24/05/11 21:41:16 WARN DAGScheduler: Broadcasting large task binary with size 1638.1 KiB\n",
      "24/05/11 21:41:20 WARN DAGScheduler: Broadcasting large task binary with size 1666.8 KiB\n",
      "24/05/11 21:41:26 WARN DAGScheduler: Broadcasting large task binary with size 1693.5 KiB\n",
      "24/05/11 21:41:33 WARN DAGScheduler: Broadcasting large task binary with size 1716.1 KiB\n",
      "24/05/11 21:41:41 WARN DAGScheduler: Broadcasting large task binary with size 1228.8 KiB\n",
      "24/05/11 21:41:48 WARN DAGScheduler: Broadcasting large task binary with size 1021.4 KiB\n",
      "24/05/11 21:41:48 WARN DAGScheduler: Broadcasting large task binary with size 1052.4 KiB\n",
      "24/05/11 21:41:48 WARN DAGScheduler: Broadcasting large task binary with size 1088.3 KiB\n",
      "24/05/11 21:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1118.4 KiB\n",
      "24/05/11 21:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1151.5 KiB\n",
      "24/05/11 21:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1183.3 KiB\n",
      "24/05/11 21:41:49 WARN DAGScheduler: Broadcasting large task binary with size 1217.5 KiB\n",
      "24/05/11 21:41:50 WARN DAGScheduler: Broadcasting large task binary with size 1256.2 KiB\n",
      "24/05/11 21:41:50 WARN DAGScheduler: Broadcasting large task binary with size 1293.3 KiB\n",
      "24/05/11 21:41:50 WARN DAGScheduler: Broadcasting large task binary with size 1333.5 KiB\n",
      "24/05/11 21:41:50 WARN DAGScheduler: Broadcasting large task binary with size 1369.9 KiB\n",
      "24/05/11 21:41:51 WARN DAGScheduler: Broadcasting large task binary with size 1402.6 KiB\n",
      "24/05/11 21:41:51 WARN DAGScheduler: Broadcasting large task binary with size 1439.7 KiB\n",
      "24/05/11 21:41:51 WARN DAGScheduler: Broadcasting large task binary with size 1475.3 KiB\n",
      "24/05/11 21:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1515.0 KiB\n",
      "24/05/11 21:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1551.4 KiB\n",
      "24/05/11 21:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1589.2 KiB\n",
      "24/05/11 21:41:52 WARN DAGScheduler: Broadcasting large task binary with size 1627.6 KiB\n",
      "24/05/11 21:41:53 WARN DAGScheduler: Broadcasting large task binary with size 1665.2 KiB\n",
      "24/05/11 21:41:53 WARN DAGScheduler: Broadcasting large task binary with size 1702.3 KiB\n",
      "24/05/11 21:41:53 WARN DAGScheduler: Broadcasting large task binary with size 1732.2 KiB\n",
      "24/05/11 21:41:54 WARN DAGScheduler: Broadcasting large task binary with size 1765.9 KiB\n",
      "24/05/11 21:41:54 WARN DAGScheduler: Broadcasting large task binary with size 1798.7 KiB\n",
      "24/05/11 21:41:54 WARN DAGScheduler: Broadcasting large task binary with size 1833.0 KiB\n",
      "24/05/11 21:41:55 WARN DAGScheduler: Broadcasting large task binary with size 1869.9 KiB\n"
     ]
    }
   ],
   "source": [
    "cvModel1 = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f07610e3-e57c-49c2-81c2-9cfd2213fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.962274061541674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/11 21:42:00 WARN DAGScheduler: Broadcasting large task binary with size 1315.2 KiB\n"
     ]
    }
   ],
   "source": [
    "test_pred = cvModel1.transform(test_data)\n",
    "f1_score = evaluator.evaluate(test_pred)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b04040-bf45-475f-b8c4-9e007fc60a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5007bd5-cf68-4170-b2a7-2747cdea699e",
   "metadata": {},
   "source": [
    "### Lets try Word2vec with naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f87c3ef-aaff-4566-be46-223eaa8befdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "#Remove Stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "\n",
    "# Word2Vec\n",
    "word2Vec = Word2Vec(inputCol=\"filtered\", outputCol=\"vectorized\", vectorSize=10, minCount=0)\n",
    "\n",
    "# W2Vec Dataframes typically has negative values so we will correct for that here so that we can use the Naive Bayes classifier\n",
    "scaler = MinMaxScaler(inputCol=\"vectorized\", outputCol=\"feature\")\n",
    "\n",
    "\n",
    "#Convert column class to 0,1\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "\n",
    "#Using Vector Assmbeler to creater features column\n",
    "vectorAssm = VectorAssembler(inputCols=['feature','length'] , outputCol='features')\n",
    "\n",
    "#Creating model\n",
    "nv = NaiveBayes()\n",
    "\n",
    "# Creating pipeline with word2vec instead of tf-idf\n",
    "stages = [regexTokenizer , remover  , word2Vec ,scaler , indexer , vectorAssm , nv ]\n",
    "pl = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49ce6586-036a-4eb2-b0ae-c083416a2c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pl.fit(train_data)\n",
    "train_pred = model.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27328fc3-3244-4cde-98d6-4e5c1c23978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8740710998140007"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.transform(test_data)\n",
    "test_pred.cache()\n",
    "evaluator.evaluate(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd65802-0c14-4c3a-b361-2589350ef3ed",
   "metadata": {},
   "source": [
    "### as we see still tf-idf better than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68582168-ce2a-4557-97de-309e5ab713b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
